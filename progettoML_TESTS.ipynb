{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Dependencies"
      ],
      "metadata": {
        "id": "GdvvZJxfVmy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install torch torchvision\n",
        "%pip install opencv-python\n",
        "%pip install numpy\n",
        "%pip install pillow\n",
        "%pip install matplotlib"
      ],
      "metadata": {
        "collapsed": true,
        "id": "vA1wwxcuJnUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# imports"
      ],
      "metadata": {
        "id": "Gv2WeM82ViRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T"
      ],
      "metadata": {
        "id": "U_5EFIyQVg-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Augmentation and Transforms\n",
        "# -----------------------------\n",
        "class Augmentations:\n",
        "    @staticmethod\n",
        "    def get_train_transforms():\n",
        "        return T.Compose([\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.5], std=[0.5]),\n",
        "        ])\n",
        "\n",
        "    @staticmethod\n",
        "    def get_test_transforms():\n",
        "        return T.Compose([\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.5], std=[0.5]),\n",
        "        ])\n",
        "\n",
        "# -----------------------------\n",
        "# Lightweight Preprocessing: Grayscale Only\n",
        "# -----------------------------\n",
        "def lightweight_preprocess(img, target_size=(50, 50)):\n",
        "    \"\"\"\n",
        "    Converts BGR image to grayscale and resizes.\n",
        "    Returns image as shape (1, H, W) with dtype uint8.\n",
        "    \"\"\"\n",
        "    if img is None:\n",
        "        return None\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gray = cv2.resize(gray, target_size)\n",
        "    gray = np.expand_dims(gray, axis=0)  # (1, H, W)\n",
        "    return gray\n",
        "\n",
        "# -----------------------------\n",
        "# Dataset\n",
        "# -----------------------------\n",
        "class RPSDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.samples = []\n",
        "        self.class_map = {'rock': 0, 'paper': 1, 'scissors': 2}\n",
        "        self.transform = transform\n",
        "        skipped = 0\n",
        "\n",
        "        for label in self.class_map.keys():\n",
        "            class_folder = os.path.join(root_dir, label)\n",
        "            if not os.path.exists(class_folder):\n",
        "                continue\n",
        "            for filename in os.listdir(class_folder):\n",
        "                if filename.lower().endswith((\".jpg\", \".png\")):\n",
        "                    path = os.path.join(class_folder, filename)\n",
        "                    img = cv2.imread(path)\n",
        "                    proc_img = lightweight_preprocess(img)\n",
        "                    if proc_img is not None:\n",
        "                        self.samples.append((path, self.class_map[label]))\n",
        "                    else:\n",
        "                        skipped += 1\n",
        "        if skipped > 0:\n",
        "            print(f\"Skipped {skipped} images due to failed loading/preprocessing\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        img = cv2.imread(img_path)\n",
        "        proc_img = lightweight_preprocess(img)\n",
        "        if proc_img is None:\n",
        "            proc_img = np.zeros((1, 50, 50), dtype=np.uint8)\n",
        "        # To PIL Image for transform (expects HWC), so squeeze channel\n",
        "        img_pil = Image.fromarray(proc_img[0])\n",
        "        if self.transform:\n",
        "            img_tensor = self.transform(img_pil)\n",
        "        else:\n",
        "            img_tensor = torch.tensor(proc_img, dtype=torch.float32) / 255.0\n",
        "        return img_tensor, label\n",
        "\n",
        "# -----------------------------\n",
        "# Model\n",
        "# -----------------------------\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, input_size=50, num_classes=3):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, 3, padding=1),  # in_channels=1 for grayscale\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(8, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        conv_output_size = (input_size // 4) * (input_size // 4) * 16\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(conv_output_size, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# -----------------------------\n",
        "# Training Logic\n",
        "# -----------------------------\n",
        "class Trainer:\n",
        "    def __init__(self, model, train_loader, test_loader=None, device=None, lr=0.001):\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device or torch.device(\n",
        "            \"cuda\" if hasattr(torch, \"cuda\") and torch.mps.is_available()\n",
        "            else \"cuda\" if torch.cuda.is_available()\n",
        "            else \"cpu\"\n",
        "        )\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def train(self, num_epochs=10):\n",
        "        for epoch in range(num_epochs):\n",
        "            self.model.train()\n",
        "            total_loss = 0\n",
        "            for imgs, labels in self.train_loader:\n",
        "                imgs, labels = imgs.to(self.device), labels.to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(imgs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "            avg_loss = total_loss / len(self.train_loader)\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "            if self.test_loader:\n",
        "                self.evaluate()\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in self.test_loader:\n",
        "                imgs, labels = imgs.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(imgs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    def save_model(self, path):\n",
        "        torch.save(self.model.state_dict(), path)\n",
        "        print(f\"Model saved at {path}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Main entry\n",
        "# -----------------------------\n",
        "def main():\n",
        "    train_dir = \"/content/drive/MyDrive/sassocartaforbici/dataset_solo_persone/train\"\n",
        "    test_dir = \"/content/drive/MyDrive/sassocartaforbici/dataset_solo_persone/test\"\n",
        "\n",
        "    # Datasets\n",
        "    train_dataset = RPSDataset(\n",
        "        root_dir=train_dir,\n",
        "        transform=Augmentations.get_train_transforms()\n",
        "    )\n",
        "    test_dataset = RPSDataset(\n",
        "        root_dir=test_dir,\n",
        "        transform=Augmentations.get_test_transforms()\n",
        "    )\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Model\n",
        "    model = SimpleCNN(input_size=50, num_classes=3)\n",
        "\n",
        "    # Trainer\n",
        "    trainer = Trainer(model, train_loader, test_loader)\n",
        "    trainer.train(num_epochs=10)\n",
        "    trainer.save_model(\"model_p_n.pth\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NPaNW6hRNJM",
        "outputId": "c1ad4e02-b2ed-4e71-b462-1e6c42ad2de7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.7296\n",
            "Test Accuracy: 50.63%\n",
            "Epoch 2/10, Loss: 0.6571\n",
            "Test Accuracy: 64.71%\n",
            "Epoch 3/10, Loss: 0.6126\n",
            "Test Accuracy: 67.44%\n",
            "Epoch 4/10, Loss: 0.5562\n",
            "Test Accuracy: 67.44%\n",
            "Epoch 5/10, Loss: 0.5230\n",
            "Test Accuracy: 73.11%\n",
            "Epoch 6/10, Loss: 0.4645\n",
            "Test Accuracy: 73.11%\n",
            "Epoch 7/10, Loss: 0.4294\n",
            "Test Accuracy: 78.15%\n",
            "Epoch 8/10, Loss: 0.3897\n",
            "Test Accuracy: 80.46%\n",
            "Epoch 9/10, Loss: 0.3490\n",
            "Test Accuracy: 80.04%\n",
            "Epoch 10/10, Loss: 0.3192\n",
            "Test Accuracy: 80.25%\n",
            "Model saved at model_p_n.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tests"
      ],
      "metadata": {
        "id": "sbgk4IoZbeez"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## \"optimizations\""
      ],
      "metadata": {
        "id": "JjJkrlunfl-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Augmentation and Transforms \"Optimizations\"\n",
        "# -----------------------------\n",
        "class Augmentations:\n",
        "    @staticmethod\n",
        "    def get_transforms():\n",
        "        return T.Compose([\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.5], std=[0.5]),\n",
        "            ])\n",
        "\n",
        "# -----------------------------\n",
        "# Improved Preprocessing Pipeline\n",
        "# -----------------------------\n",
        "def skin_mask_ycrcb(img):\n",
        "    ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
        "    lower = np.array([0, 133, 77], dtype=np.uint8)\n",
        "    upper = np.array([255, 173, 127], dtype=np.uint8)\n",
        "    mask = cv2.inRange(ycrcb, lower, upper)\n",
        "    return mask\n",
        "\n",
        "def preprocess_image(img, bg_subtractor=None, size=(64, 64)):\n",
        "    if img is None:\n",
        "        return None\n",
        "\n",
        "    # Step 1: Skin detection\n",
        "    skin = skin_mask_ycrcb(img)\n",
        "\n",
        "    # Step 2: Background subtraction\n",
        "    if bg_subtractor:\n",
        "        fg_mask = bg_subtractor.apply(img)\n",
        "        combined = cv2.bitwise_and(skin, fg_mask)\n",
        "    else:\n",
        "        combined = skin\n",
        "\n",
        "    # Step 3: Smooth and threshold\n",
        "    blurred = cv2.GaussianBlur(combined, (5, 5), 0)\n",
        "    _, thresh = cv2.threshold(blurred, 50, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Step 4: Resize and convert to grayscale\n",
        "    resized = cv2.resize(thresh, size)\n",
        "    final = np.expand_dims(resized, axis=0)  # shape: (1, H, W)\n",
        "    return final\n",
        "\n",
        "# -----------------------------\n",
        "# Dataset\n",
        "# -----------------------------\n",
        "class RPSDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, bg_subtractor=None):\n",
        "        self.samples = []\n",
        "        self.class_map = {'rock': 0, 'paper': 1, 'scissors': 2}\n",
        "        self.transform = transform\n",
        "        self.bg_subtractor = bg_subtractor\n",
        "\n",
        "        for label in self.class_map:\n",
        "            folder = os.path.join(root_dir, label)\n",
        "            if not os.path.exists(folder):\n",
        "                continue\n",
        "            for fname in os.listdir(folder):\n",
        "                if fname.lower().endswith(('.jpg', '.png')):\n",
        "                    path = os.path.join(folder, fname)\n",
        "                    self.samples.append((path, self.class_map[label]))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.samples[idx]\n",
        "        img = cv2.imread(path)\n",
        "        proc = preprocess_image(img, self.bg_subtractor)\n",
        "        if proc is None:\n",
        "            proc = np.zeros((1, 64, 64), dtype=np.uint8)\n",
        "        img_pil = Image.fromarray(proc[0])\n",
        "        if self.transform:\n",
        "            img_tensor = self.transform(img_pil)\n",
        "        else:\n",
        "            img_tensor = torch.tensor(proc, dtype=torch.float32) / 255.0\n",
        "        return img_tensor, label\n",
        "\n",
        "# -----------------------------\n",
        "# MobileNet-style Depthwise CNN\n",
        "# -----------------------------\n",
        "class DepthwiseSeparableConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super().__init__()\n",
        "        self.depthwise = nn.Conv2d(in_ch, in_ch, kernel_size=3, padding=1, groups=in_ch)\n",
        "        self.pointwise = nn.Conv2d(in_ch, out_ch, kernel_size=1)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.depthwise(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.pointwise(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "class SimpleMobileNet(nn.Module):\n",
        "    def __init__(self, num_classes=3):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "                DepthwiseSeparableConv(1, 8),\n",
        "                nn.MaxPool2d(2),\n",
        "                DepthwiseSeparableConv(8, 16),\n",
        "                nn.MaxPool2d(2),\n",
        "                )\n",
        "        self.classifier = nn.Sequential(\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(16 * 16 * 16, 32),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(32, num_classes)\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# -----------------------------\n",
        "# Training and Evaluation\n",
        "# -----------------------------\n",
        "class Trainer:\n",
        "    def __init__(self, model, train_loader, test_loader=None, device=None, lr=0.001):\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
        "\n",
        "    def train(self, epochs=10):\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            running_loss = 0\n",
        "            for imgs, labels in self.train_loader:\n",
        "                imgs, labels = imgs.to(self.device), labels.to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(imgs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                running_loss += loss.item()\n",
        "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(self.train_loader):.4f}\")\n",
        "            self.evaluate()\n",
        "\n",
        "    def evaluate(self):\n",
        "        if not self.test_loader:\n",
        "            return\n",
        "        self.model.eval()\n",
        "        correct = total = 0\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in self.test_loader:\n",
        "                imgs, labels = imgs.to(self.device), labels.to(self.device)\n",
        "                preds = self.model(imgs).argmax(dim=1)\n",
        "                correct += (preds == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "        acc = 100 * correct / total\n",
        "        print(f\"Test Accuracy: {acc:.2f}%\")\n",
        "\n",
        "    def save_model(self, path=\"model_mobile.pth\", torchscript_path=\"model_mobile.pt\"):\n",
        "        torch.save(self.model.state_dict(), path)\n",
        "        print(f\"Model saved: {path}\")\n",
        "        example = torch.rand(1, 1, 64, 64).to(self.device)\n",
        "        scripted = torch.jit.trace(self.model, example)\n",
        "        scripted.save(torchscript_path)\n",
        "        print(f\"TorchScript saved: {torchscript_path}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Main\n",
        "# -----------------------------\n",
        "def main():\n",
        "    train_path = \"/content/drive/MyDrive/sassocartaforbici/dataset_solo_persone/train\"\n",
        "    test_path = \"/content/drive/MyDrive/sassocartaforbici/dataset_solo_persone/test\"\n",
        "\n",
        "    bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=100, varThreshold=50)\n",
        "\n",
        "    train_set = RPSDataset(train_path, transform=Augmentations.get_transforms(), bg_subtractor=bg_subtractor)\n",
        "    test_set = RPSDataset(test_path, transform=Augmentations.get_transforms(), bg_subtractor=bg_subtractor)\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_set, batch_size=32)\n",
        "\n",
        "    model = SimpleMobileNet(num_classes=3)\n",
        "    trainer = Trainer(model, train_loader, test_loader)\n",
        "    trainer.train(epochs=10)\n",
        "    trainer.save_model()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlZphIEPbd8n",
        "outputId": "af55a776-d695-4283-afb1-760045274589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.7367\n",
            "Test Accuracy: 50.63%\n",
            "Epoch 2/10, Loss: 0.6939\n",
            "Test Accuracy: 50.63%\n",
            "Epoch 3/10, Loss: 0.6734\n",
            "Test Accuracy: 61.55%\n",
            "Epoch 4/10, Loss: 0.6460\n",
            "Test Accuracy: 57.56%\n",
            "Epoch 5/10, Loss: 0.6336\n",
            "Test Accuracy: 63.03%\n",
            "Epoch 6/10, Loss: 0.6094\n",
            "Test Accuracy: 68.70%\n",
            "Epoch 7/10, Loss: 0.5915\n",
            "Test Accuracy: 67.65%\n",
            "Epoch 8/10, Loss: 0.6084\n",
            "Test Accuracy: 62.18%\n",
            "Epoch 9/10, Loss: 0.5884\n",
            "Test Accuracy: 66.81%\n",
            "Epoch 10/10, Loss: 0.5784\n",
            "Test Accuracy: 67.86%\n",
            "Model saved: model_mobile.pth\n",
            "TorchScript saved: model_mobile.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## no preproc + indiano"
      ],
      "metadata": {
        "id": "ISJ-ALTZV_w-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Augmentation and Transforms \"no preproc + indiano\"\n",
        "# -----------------------------\n",
        "class Augmentations:\n",
        "    @staticmethod\n",
        "    def get_train_transforms():\n",
        "        return T.Compose([\n",
        "            T.RandomResizedCrop(50, scale=(0.8, 1.2), ratio=(0.9, 1.1)),\n",
        "            T.RandomRotation(30),\n",
        "            T.ColorJitter(brightness=0.3, contrast=0.3),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.5], std=[0.5]),\n",
        "        ])\n",
        "\n",
        "    @staticmethod\n",
        "    def get_test_transforms():\n",
        "        return T.Compose([\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.5], std=[0.5]),\n",
        "        ])\n",
        "\n",
        "# -----------------------------\n",
        "# Dataset\n",
        "# -----------------------------\n",
        "class RPSDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, class_map=None):\n",
        "        self.samples = []\n",
        "        self.transform = transform\n",
        "        # You can modify this mapping for your specific classes\n",
        "        self.class_map = class_map or {'rock': 0, 'paper': 1, 'scissors': 2}\n",
        "        skipped = 0\n",
        "\n",
        "        for label in self.class_map.keys():\n",
        "            class_folder = os.path.join(root_dir, label)\n",
        "            if not os.path.exists(class_folder):\n",
        "                continue\n",
        "            for filename in os.listdir(class_folder):\n",
        "                if filename.lower().endswith((\".jpg\", \".png\")):\n",
        "                    path = os.path.join(class_folder, filename)\n",
        "                    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "                    if img is not None:\n",
        "                        self.samples.append((path, self.class_map[label]))\n",
        "                    else:\n",
        "                        skipped += 1\n",
        "        if skipped > 0:\n",
        "            print(f\"Skipped {skipped} images due to failed loading\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            img = np.zeros((50, 50), dtype=np.uint8)\n",
        "        img = cv2.resize(img, (50, 50))\n",
        "        img_pil = Image.fromarray(img)\n",
        "        if self.transform:\n",
        "            img_tensor = self.transform(img_pil)\n",
        "        else:\n",
        "            img_tensor = torch.tensor(img, dtype=torch.float32).unsqueeze(0) / 255.0\n",
        "        return img_tensor, label\n",
        "\n",
        "# -----------------------------\n",
        "# Model\n",
        "# -----------------------------\n",
        "class LightweightCNN(nn.Module):\n",
        "    def __init__(self, image_x=50, image_y=50, num_of_classes=3):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, padding=2)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=5, stride=5, padding=2)\n",
        "\n",
        "        # Dynamically determine flatten dimension\n",
        "        dummy = torch.zeros(1, 1, image_x, image_y)\n",
        "        x = self.pool1(F.relu(self.conv1(dummy)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        flat_dim = x.view(1, -1).shape[1]\n",
        "\n",
        "        self.fc1 = nn.Linear(flat_dim, 1024)\n",
        "        self.dropout = nn.Dropout(0.6)\n",
        "        self.fc2 = nn.Linear(1024, num_of_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool2(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# -----------------------------\n",
        "# Training Logic\n",
        "# -----------------------------\n",
        "class Trainer:\n",
        "    def __init__(self, model, train_loader, test_loader=None, device=None, lr=0.001):\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device or torch.device(\n",
        "            \"cuda\" if torch.cuda.is_available()\n",
        "            else \"cpu\"\n",
        "        )\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def train(self, num_epochs=10):\n",
        "        for epoch in range(num_epochs):\n",
        "            self.model.train()\n",
        "            total_loss = 0.0\n",
        "            for imgs, labels in self.train_loader:\n",
        "                imgs, labels = imgs.to(self.device), labels.to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(imgs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "            avg_loss = total_loss / len(self.train_loader)\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "            if self.test_loader:\n",
        "                self.evaluate()\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in self.test_loader:\n",
        "                imgs, labels = imgs.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(imgs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    def save_model(self, path):\n",
        "        torch.save(self.model.state_dict(), path)\n",
        "        print(f\"Model saved at {path}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Main entry\n",
        "# -----------------------------\n",
        "def main():\n",
        "    train_dir = \"/content/drive/MyDrive/sassocartaforbici/dataset_solo_persone/train\"\n",
        "    test_dir = \"/content/drive/MyDrive/sassocartaforbici/dataset_solo_persone/test\"\n",
        "    image_x, image_y = 50, 50\n",
        "    num_classes = 3\n",
        "    class_map = {'rock': 0, 'paper': 1, 'scissors': 2}\n",
        "\n",
        "    # Datasets\n",
        "    train_dataset = RPSDataset(\n",
        "        root_dir=train_dir,\n",
        "        transform=Augmentations.get_train_transforms(),\n",
        "        class_map=class_map\n",
        "    )\n",
        "    test_dataset = RPSDataset(\n",
        "        root_dir=test_dir,\n",
        "        transform=Augmentations.get_test_transforms(),\n",
        "        class_map=class_map\n",
        "    )\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Model\n",
        "    model = LightweightCNN(image_x=image_x, image_y=image_y, num_of_classes=num_classes)\n",
        "\n",
        "    # Trainer\n",
        "    trainer = Trainer(model, train_loader, test_loader)\n",
        "    trainer.train(num_epochs=10)\n",
        "    trainer.save_model(\"model_np_i.pth\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdFBmVijUnvq",
        "outputId": "6adb90fc-49c2-4adb-c6b4-3639e3f134f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.7458\n",
            "Test Accuracy: 56.93%\n",
            "Epoch 2/10, Loss: 0.6864\n",
            "Test Accuracy: 58.82%\n",
            "Epoch 3/10, Loss: 0.6715\n",
            "Test Accuracy: 65.76%\n",
            "Epoch 4/10, Loss: 0.6586\n",
            "Test Accuracy: 65.55%\n",
            "Epoch 5/10, Loss: 0.6532\n",
            "Test Accuracy: 67.02%\n",
            "Epoch 6/10, Loss: 0.6317\n",
            "Test Accuracy: 68.91%\n",
            "Epoch 7/10, Loss: 0.6296\n",
            "Test Accuracy: 72.06%\n",
            "Epoch 8/10, Loss: 0.6064\n",
            "Test Accuracy: 64.92%\n",
            "Epoch 9/10, Loss: 0.6029\n",
            "Test Accuracy: 72.06%\n",
            "Epoch 10/10, Loss: 0.5738\n",
            "Test Accuracy: 73.53%\n",
            "Model saved at model_np_i.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## no preproc + normal"
      ],
      "metadata": {
        "id": "6wUWxhx-V3Wz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# Augmentation and Transforms \"no preproc + normal\"\n",
        "# -----------------------------\n",
        "class Augmentations:\n",
        "    @staticmethod\n",
        "    def get_train_transforms():\n",
        "        # For raw color images (3 channels)\n",
        "        return T.Compose([\n",
        "            T.RandomResizedCrop(50, scale=(0.8, 1.2), ratio=(0.9, 1.1)),\n",
        "            T.RandomRotation(30),\n",
        "            T.ColorJitter(brightness=0.3, contrast=0.3),\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "        ])\n",
        "\n",
        "    @staticmethod\n",
        "    def get_test_transforms():\n",
        "        return T.Compose([\n",
        "            T.ToTensor(),\n",
        "            T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "        ])\n",
        "\n",
        "# -----------------------------\n",
        "# Dataset\n",
        "# -----------------------------\n",
        "class RPSDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.samples = []\n",
        "        self.class_map = {'rock': 0, 'paper': 1, 'scissors': 2}\n",
        "        self.transform = transform\n",
        "        skipped = 0\n",
        "\n",
        "        for label in self.class_map.keys():\n",
        "            class_folder = os.path.join(root_dir, label)\n",
        "            if not os.path.exists(class_folder):\n",
        "                continue\n",
        "            for filename in os.listdir(class_folder):\n",
        "                if filename.lower().endswith((\".jpg\", \".png\")):\n",
        "                    path = os.path.join(class_folder, filename)\n",
        "                    img = cv2.imread(path)\n",
        "                    if img is not None:\n",
        "                        self.samples.append((path, self.class_map[label]))\n",
        "                    else:\n",
        "                        skipped += 1\n",
        "        if skipped > 0:\n",
        "            print(f\"Skipped {skipped} images due to failed loading\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            # fallback to blank image with 3 channels\n",
        "            img = np.zeros((50, 50, 3), dtype=np.uint8)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        img = cv2.resize(img, (50, 50))\n",
        "        img_pil = Image.fromarray(img)\n",
        "        if self.transform:\n",
        "            img_tensor = self.transform(img_pil)\n",
        "        else:\n",
        "            img_tensor = torch.tensor(img.transpose(2, 0, 1), dtype=torch.float32) / 255.0\n",
        "        return img_tensor, label\n",
        "\n",
        "# -----------------------------\n",
        "# Model\n",
        "# -----------------------------\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, input_size=50, num_classes=3):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, 3, padding=1),  # in_channels=3 for RGB\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        conv_output_size = (input_size // 4) * (input_size // 4) * 32\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(conv_output_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# -----------------------------\n",
        "# Training Logic\n",
        "# -----------------------------\n",
        "class Trainer:\n",
        "    def __init__(self, model, train_loader, test_loader=None, device=None, lr=0.001):\n",
        "        self.model = model\n",
        "        self.train_loader = train_loader\n",
        "        self.test_loader = test_loader\n",
        "        self.device = device or torch.device(\n",
        "            \"cuda\" if hasattr(torch, \"cuda\") and torch.mps.is_available()\n",
        "            else \"cuda\" if torch.cuda.is_available()\n",
        "            else \"cpu\"\n",
        "        )\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def train(self, num_epochs=10):\n",
        "        for epoch in range(num_epochs):\n",
        "            self.model.train()\n",
        "            total_loss = 0\n",
        "            for imgs, labels in self.train_loader:\n",
        "                imgs, labels = imgs.to(self.device), labels.to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "                outputs = self.model(imgs)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "            avg_loss = total_loss / len(self.train_loader)\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
        "            if self.test_loader:\n",
        "                self.evaluate()\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in self.test_loader:\n",
        "                imgs, labels = imgs.to(self.device), labels.to(self.device)\n",
        "                outputs = self.model(imgs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    def save_model(self, path):\n",
        "        torch.save(self.model.state_dict(), path)\n",
        "        print(f\"Model saved at {path}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Main entry\n",
        "# -----------------------------\n",
        "def main():\n",
        "    train_dir = \"/content/drive/MyDrive/sassocartaforbici/dataset_solo_persone/train\"\n",
        "    test_dir = \"/content/drive/MyDrive/sassocartaforbici/dataset_solo_persone/test\"\n",
        "\n",
        "    # Datasets\n",
        "    train_dataset = RPSDataset(\n",
        "        root_dir=train_dir,\n",
        "        transform=Augmentations.get_train_transforms()\n",
        "    )\n",
        "    test_dataset = RPSDataset(\n",
        "        root_dir=test_dir,\n",
        "        transform=Augmentations.get_test_transforms()\n",
        "    )\n",
        "\n",
        "    # DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Model\n",
        "    model = SimpleCNN(input_size=50, num_classes=3)\n",
        "\n",
        "    # Trainer\n",
        "    trainer = Trainer(model, train_loader, test_loader)\n",
        "    trainer.train(num_epochs=10)\n",
        "    trainer.save_model(\"model_np_n.pth\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yNyiIiWJD9W",
        "outputId": "8edb8c47-2ffe-45b3-d480-64a0ecfd0513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.7161\n",
            "Test Accuracy: 59.03%\n",
            "Epoch 2/10, Loss: 0.6774\n",
            "Test Accuracy: 63.66%\n",
            "Epoch 3/10, Loss: 0.6577\n",
            "Test Accuracy: 65.76%\n",
            "Epoch 4/10, Loss: 0.6488\n",
            "Test Accuracy: 60.29%\n",
            "Epoch 5/10, Loss: 0.6292\n",
            "Test Accuracy: 70.17%\n",
            "Epoch 6/10, Loss: 0.6057\n",
            "Test Accuracy: 72.06%\n",
            "Epoch 7/10, Loss: 0.5762\n",
            "Test Accuracy: 73.53%\n",
            "Epoch 8/10, Loss: 0.5519\n",
            "Test Accuracy: 76.47%\n",
            "Epoch 9/10, Loss: 0.5732\n",
            "Test Accuracy: 71.22%\n",
            "Epoch 10/10, Loss: 0.5149\n",
            "Test Accuracy: 75.21%\n",
            "Model saved at model_np_n.pth\n"
          ]
        }
      ]
    }
  ]
}